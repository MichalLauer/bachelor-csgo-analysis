\chapter{Teoretická část}
V následující části jsou popsány jak teoretické metody pro vizualizaci dat, tak i tvar, forma a vyhodnocení logistického regresního modelu. 
Ke každé části, která zpracovává data pomocí grafu, je přidána praktická ukázka s popisem a vysvětlením.

\section{Vizualizace dat} \label{sec:vizualizace_dat}
\subsection{Bodový graf}
Bodový graf slouží k zobrazení vztahu dvou kvantitativních proměnných. Zpravidla se vysvětlovaná proměnná přiřazuje k ose Y,
zatímco proměnná vysvětlující se nachází na ose X. Vysvětlovaná (nezávislá) proměnná je ta proměnná, která má být předpovězena.
Vysvětlující proměnná se naopak snaží vysvětlovanou proměnnou předpovědět či popsat. Díky zobrazení vysvětlované a vysvětlující proměnné lze na
bodovém grafu vidět vztah mezi proměnnými (např. lineární, kvadratický, logaritmický).
  
\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/bodovy_graf_mtcars.png}
    \caption{Bodový graf hmotnosti a míle za galon} 
    \label{fig:bodovy_graf_mtcars}
\end{figure}

Obrázek \ref{fig:bodovy_graf_mtcars} zobrazuje negativní lineární vztah mezi hmotností vozidla a mílemi ujetými za galon.

\subsection{Sloupcový graf}
Sloupcový graf slouží k zobrazení četnosti kategorií. Na jednu osu (zpravidla osu X) se položí možné kategorie. Na druhé ose je pak sledovaná statistika. Je možné sledovat 
nejen četnost, ale i průměr či kteroukoli jinou statistiku, kterou bude možné na ose zobrazit. Nejčastěji se pomocí sloupcového grafu porovnává absolutní četnost přes kategorie.
Řazení kategorií se dále odvíjí od toho, zda je daná proměnná ordinální, či nominální. V případě nominální proměnné se sloupce řadí podle absolutní četnosti, a to od nejvyšší po
nejnižší. V případě ordinální proměnné se zachovává přirozené řazení. Příkladem sloupcového grafu je graf na obrázku \ref{fig:sloupcovy_graf_mtcars}, který porovnává průměrnou
hrubou koňskou sílu s počtem válců. Ukazuje také závislost hrubé koňské síly na počtu válců.

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/sloupcovy_graf_mtcars.png}
    \caption{Sloupcový graf počtu válců a průměrné hrubé koňské síly} 
    \label{fig:sloupcovy_graf_mtcars}
\end{figure}

\subsection{Histogram}

Histogram je speciálním typem sloupcového grafu. Hlavní rozdíl mezi nimi spočívá v tom, že histogram zobrazuje rozdělení spojité proměnné a mezi sloupci není žádná mezera.
K vytvoření histogramu je třeba data sloučit do skupin o určité šířce. Správný výběr počtu skupin je kritický, jelikož může velmi silně ovlivnit interpretaci dat. Pokud
se vybere příliš malý počet skupin, data se příliš shluknou a může se ztratit důležitý vztah. Pokud se ovšem vybere příliš vysoký počet skupin, v datech bude obtížné najít nějaký
obecný vztah či trend, viz obrázek \ref{fig:histogram_porovnani_mtcars}.

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/histogram_porovnani_mtcars.png}
    \caption{Porovnání histogramů s různým počtem skupin} 
    \label{fig:histogram_porovnani_mtcars}
\end{figure}

Pro zjištění vhodného počtu skupin existuje mnoho způsobů. Nejznámějším je takzvané Sturgesovo pravidlo, které se spočítá následujícím vztahem:

\begin{equation}
    \label{eq:sturgesovo_pravidlo}
    k \text{ } \dot{\mathbf{=}} \text{ } 1 + 3,3 * log_{10}(n),
\end{equation}

kde $k$ je přibližný počet skupin a $n$ je počet pozorování. Druhým parametrem nezbytným pro tvorbu histogramu je šířka skupiny.
Ta by měla být ideálně stejná pro všechny skupiny. Pokud tomu tak není, histogram může být zavádějící a čtenář mu nemusí plně rozumět.
Pro určení počtu skupin má šířka skupiny následující tvar:

\begin{equation}
    w = \frac{max(X) - min(X)}{k},
\end{equation}

kde $X$ je zobrazovaná proměnná, $k$ je počet skupin a $w$ je výsledná šířka intervalu. 
Je však nutné podotknout, že není pravidlem se danými výpočty řídit. Výsledný
sloupcový graf je nutné přizpůsobit konkrétnímu datovému souboru.

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/histogram_mtcars_sturges.png}
    \caption{Histogram s počtem skupin dle Sturgesova pravidla} 
    \label{fig:histogram_mtcars_sturges}
\end{figure}

Obrázek \ref{fig:histogram_mtcars_sturges} ukazuje histogram proměnné míle za galon. Počet sloupců je vypočítán podle Sturgesova pravidla,
vysvětleno v \ref{eq:sturgesovo_pravidlo}. 

\subsection{Krabičkový graf}
\subsubsection{Pětičíselné shrnutí}
Pětičíselné shrnutí je číselná tabulka, která pomocí pěti různých čísel shrnuje seřazenou číselnou řadu. Základním statistickým nástrojem pro
vytvoření takové tabulky jsou percentily. Hodnota $P$-tého percentilu označuje číslo, které rozděluje seřazenou číselnou řadu na dva intervaly. 
První interval obsahuje $P*100 \%$ číselné řady a druhý analogicky $(1-P)*100\,\% $. Různé hodnoty percentilů mohou mít specifičtější pojmenování a značí se $Q_P$.
Percentil $P = 0,5$ se označuje jako medián a rozděluje seřazenou číselnou řadu na polovinu. Percentily, kde $P = 0,25$ nebo $P = 0,75$, se označují
jako kvartily a značí se $Q_{1}$ a $Q_{3}$. Oba tyto typy kvartilů jsou použité při tvorbě tabulky.

\begin{table}[H]
    \centering
    \begin{tabular}[t]{c|c|c|c|c}
        \hline
        $Q_{0}     $ & $Q_{0,25} (Q_1) $ & $Q_{0,50}$ & $Q_{0,75} (Q_3)$ & $Q_{1}$\\
        \hline
        1,513 & 2,58125 & 3,325 & 3,61 & 5,424\\
        \hline
    \end{tabular}
    \caption{\label{tab:five-number_summary}Pětičíselné shrnutí hmotnosti vozidla (lb/1000)}
\end{table}


Příkladem pětičíselného shrnutí je tabulka \ref{tab:five-number_summary}, kde $Q_{0}$ a $Q_{1}$ označují minimum a maximum číselné řady. Kvartily $Q_{1}$, $Q_{2}$ (medián)
a $Q_{3}$ jsou čísla, která rozděluji číselnou řadu na čtvrtiny. V prvním případě, tedy $Q_1 = Q_{0,25}$, je 25\,\%  čísel menších než 1,513 a 75\,\%  dat větších. Pro kvantil
$Q_3 = Q_{0,75}$ je 75\,\%  čísel menších než 3,61 a 25\,\%  větších. $Q_{0,50}$ označuje medián a 50 \% dat je nad 3,325 a 50 \% dat pod 3,325.

\subsubsection{Krabičkový graf}
Krabičkový graf je grafické zobrazení a rozšíření pětičíselného shrnutí. Kromě grafického zobrazení pěti kvartilů  zobrazuje odlehlé a extrémní hodnoty.
V krabičkovém grafu se také nachází obdélník, který ukazuje mezikvartilové rozpětí (IQR), tedy prostředních 50\,\% dat. V obdélníku se nachází černá čára značící medián.
Z prostředního obdélníku vedou oběma směry čáry, jejichž konce značí hranici pro odlehlá pozorování. Pokud datový soubor neobsahuje žádná odlehlá pozorování, konec těchto čar
značí minimum a maximum datového souboru.
Pozorování, která jsou buď větší než horní hranice, nebo menší než spodní hranice, označujeme jako odlehlá nebo extrémní. 

\begin{align*}
    \textit{Spodní hranice } &= Q_1 - 1,5 * \textit{IQR} \\
    \textit{Horní hranice } &= Q_3 + 1,5 * \textit{IQR}
\end{align*}

Hodnoty, které spadají do intervalu $\langle Q_1 - 1,5*\textit{IQR}; Q_1 - 3*\textit{IQR}\rangle$ a $\langle Q_3 + 1,5*\textit{IQR}, Q_3 + 3*\textit{IQR} \rangle$ se nazývají
odlehlé. Hodnoty, které leží mimo tento vztah, tedy hodnoty menší než $Q_1 - 3*\textit{IQR}$ nebo větší než $Q_3 + 3*\textit{IQR}$, se nazývají hodnoty extrémní. Odlehlá
pozorování se v krabičkovém grafu většinou značí kolečkem, zatímco pozorování extrémní hvězdičkou. Díky grafickému zobrazení lze snadno porovnávat rozdělení jedné
vysvětlované kvantitativní proměnné tříděné přes několik kategorií.

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/krabickovy_graf_mtcars.png}
    \caption{Krabičkový graf hmotnosti auta pro různý počet válců} 
    \label{fig:krabickovy_graf_mtcars}
\end{figure}

Průhledná kolečka v obrázku \ref{fig:krabickovy_graf_mtcars} v kategorii osmi válců značí odlehlé hodnoty, t.j. hodnoty
v intervalu $\langle Q_3 + 1,*\textit{IQR}, Q_3 + *\textit{IQR} \rangle$.

\subsection{Korelační matice}
\subsubsection{Korelace}
Korelace popisuje směr a sílu vztahu mezi dvěma proměnnými $X$ a $Y$. Značí se $r$ a nabývá hodnot $\langle -1; 1 \rangle$.

\begin{equation}
r = \frac{n \sum_{i=1}^n x_i y_i - \sum_{i=1}^n x_i \sum_{i=1}^n y_i}
{\sqrt{(\overline{x^2} - \overline{x}^2)(\overline{y^2} - \overline{y}^2)}}
\end{equation}

Čím větší je absolutní hodnota korelace mezi proměnnou $X$ a $Y$, tím lépe lze pomocí jedné proměnné vysvětlit proměnnou druhou. Kladnost, případně zápornost korelace
pak značí směr vztahu, tedy zda proměnná $X$ s růstem proměnné $Y$ klesá, či stoupá. Pokud je korelace záporná, tedy $r < 0$, s růstem jedné proměnné klesá proměnná druhá.
Naopak při kladné korelaci, tedy $r > 0$, s růstem jedné proměnné roste i druhá.

Pokud korelace $r$ vychází kolem nuly, lineární závislost mezi proměnnými $X$ a $Y$ neexistuje. Důležité je také podotknout, že korelace neznamená kauzalitu. Pokud
existuje kladná korelace mezi proměnnou $X$ a $Y$, neznamená to, že růst jedné proměnné způsobil růst druhé proměnné.  


\subsubsection{Korelační matice}
Korelační matice je nástroj, díky kterému lze zobrazit korelaci mezi více než dvěma páry proměnných. Matice může být zobrazená pomocí grafu. V regresní analýze
je velmi užitečná kvůli předpokladu nezávislosti vysvětlujících proměnných. Pokud jsou při tvorbě modelu prediktory korelované,
vzniká problém tzv. multikolinearity. Multikolinearita je spojená s regresním modelem a v \cite{hebak_regrese_1998} je popsána následovně:
\uv{Pojem multikolinearity je velmi úzce svázán se silnou vzájemnou lineární závislostí vysvětlujících proměnných, jejímž důsledkem je špatně podmíněná matice X.}
Matice X zde značí matici prediktorů regresního modelu. V případě multikolinearity je potřeba zvýšit počet pozorování, případně jeden z vysoce korelovaných prediktorů z modelu
odebrat \cite{kleinbaum_logistic_2010}.

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/mtcars_korelace.png}
    \caption{Korelační matice} 
    \label{fig:mtcars_korelace}
\end{figure}

Graf korelační matice může mít mnoho podob. V příkladu na obrázku \ref{fig:mtcars_korelace} je zobrazená korelační matice jako teplotní mapa. Je z ní možné vypozorovat vysokou
pozitivní korelaci mezi páry proměnných \textit{cyl}, \textit{disp} a \textit{hp}. Naopak mezi proměnnou \textit{qsec} a proměnnou \textit{drat} není téměř žádná korelace.
Korelační matice je zároveň symetrická, jelikož korelace mezi $X$ a $Y$ je stejná jako korelace mezi $Y$ a $X$. Díky této vlastnosti je možné zobrazit pouze část korelační matice
pod úhlopříčkou bez ztráty jakékoliv informace.

\newpage
\section{Logistická regrese}
Logistická regrese je způsob, jakým lze popsat vztah mezi jedním, či několika prediktory a jednou binární vysvětlovanou 
proměnnou. K tomu slouží spojovací funkce, která transformuje lineární kombinaci prediktorů na index $z$. V případě
logistické regrese se tato funkce nazývá logistickou a je definovaná jako

\begin{equation}
    \label{eq:logisticka_funkce}
    f(z) = \frac{1}{1 + e^{-z}}.
\end{equation}

Obor hodnot funkce je interval $\langle 0, 1 \rangle$. Proměnná $z$ je lineární kombinací prediktorů  $X_1, X_2, ..., X_k$, 
jejich koeficientů $\beta_1, \beta_2, ..., \beta_k$ a parametru $\alpha$.

\begin{equation}
    \label{eq:linearni_kombinace_z}
    \begin{split}
        z &= \beta_0 + \beta_1 X_1 + ... + \beta_2 X_2 +\beta_k X_k \\
          &= \beta_0 + \sum_{i=1}^k \beta_i X_i
    \end{split}
\end{equation}

Mějme tedy binární vysvětlovanou proměnnou $Y$, u které hodnota $1$ značí výskyt jevu. Pravděpodobnost, že jev
vzhledem k definovaným prediktorům nastane, lze zapsat jako

\begin{equation}
    \label{eq:pravdepodobnost_y}
    P(Y = 1 \mid X_1, X_2, ..., X_k) = \frac{1}{1 + e^{- \left( \alpha + \sum_{i=1}^k \beta_i X_i \right) }},
\end{equation}

kde $\beta_0$ a $\beta_i$ jsou parametry odhadnuté z datového souboru \cite{kleinbaum_logistic_2010}.

\subsection{Interakce mezi prediktory}
Mějme logistický model, který má libovolné prediktory $x_1$ a $x_2$. Při tvorbě takového modelu se může stat, že má na výsledek vliv jak prediktor $x_1$ a prediktor
$x_2$, tak kombinace prediktoru $x_1$ a $x_2$. Kombinace prediktorů $x_1$ a $x_2$ se nazývá \textit{interakce}. Parametr interakce je pak součet parametrů pro $x_1$ a $x_2$,
tedy $\beta_1$ a $\beta_2$.

\begin{equation}
    \label{eq:interakce_dlouha}
    y = \beta_0 + \beta_1*x_1 + \beta_2*x_2 + (\beta_1 + \beta_2)*(x_1*x_2)
\end{equation}

Interakci mezi prediktory $x_1$ a $x_2$ z modelu \ref{eq:interakce_dlouha} lze označit jako nový prediktor $x_3$. Poté lze říct, že prediktor $x_3$ značí interakci mezi prediktory
$x_1$ a $x_2$.

\begin{equation}
    \label{eq:interakce}
    y = \beta_0 + \beta_1*x_1 + \beta_2*x_2 + (\beta_1 + \beta_2)*(x_3)
\end{equation}

Interakce ovlivňuje především kategoriální proměnné, jelikož každá kategorie s interakci má poté vlastní směrnici \cite{hindls_statistika_2018}.

\subsection{Interpretace parametrů}
Parametry $\beta$ značí logaritmus šance, kde $\beta_0$ je logaritmus šance v případě, že všechny prediktory jsou si teoreticky rovné $0$. Parametr $\beta_i$ značí logaritmus
šance pro prediktor $X_i$. Pokud jsou všechny prediktory konstantní a prediktor $x_i$ se změní o jednotku, přirozený logaritmus šance se změní o $\beta_i$. Toto lze pozorovat
například u binárních prediktorů, kdy typicky přítomnost daného prediktoru, značená jedničkou, změní výslednou šanci právě o odhadnutý parametr $\beta$. Pro přechod z přirozeného
logaritmu šance na šanci lze využít vztahu

\begin{equation}
\textit{šance } = e^{\beta_i}.
\end{equation}

Šance je podíl dvou pravděpodobností. Pokud bychom měli šanci jevu A oproti jevu B $2 : 1$, značí to, že výskyt jevu A je dvakrát pravděpodobnější než
výskyt jevu B a že jev A se vyskytuje ve $\frac{2}{3}$ případů. Šance $e^{\beta_i}$ tedy značí vztah mezi prediktorem $x_i$ a vysvětlovanou proměnnou $Y$. Pokud je
šance kladná, s vyšší hodnotou prediktoru $x_i$ se zvyšuje šance, že $Y = 1$. Pokud je vhodné šanci interpretovat jako pravděpodobnost, šanci lze převést pomocí
následujícího vztahu:

\begin{equation}
    \textit{pravděpodobnost jevu A} = \frac{\textit{šance jevu A}}{1 + \textit{šance jevu A}}.
\end{equation}

Pokud je potřeba interpretovat pravděpodobnost jako šanci, použije se logitová funkce

\begin{equation}
    \label{eq:logitova_funkce}
    \textit{šance jevu A} = \frac{p}{1 - p},
\end{equation}

kde $p$ je pravděpodobnost výskytu jevu A.

\subsection{Maximální pravděpodobnost}
Parametry logistického modelu v rovnici \ref{eq:pravdepodobnost_y} jsou pouze teoretické a je třeba je odhadnout. Pro odhad parametrů se při logistické regresi používá metoda
maximální věrohodnosti. Pro výpočet maximální věrohodnosti se používá věrohodnostní funkce $L(\theta)$, kde $\theta$ jsou parametry logistického modelu
$\beta_0, \beta_1, ..., \beta_k$. Pro logistickou regresi má věrohodnostní funkce tvar

\begin{equation}
    \label{eq:pravdepodobnostni_fce}
    L(\theta) = \Pi_{l = 1}^{m_1} P(X_i) \Pi_{l = m_1 + 1}^{n} (1 - P(X_i)),
\end{equation}

kde $n$ je počet pozorování a $m_1$ je počet příznivých ($Y = 1$) jevů. Funkce předpokládá, že datový soubor je seřazen tak, že prvních $m_1$ výskytů
jsou jevy příznivé. $P(X_i)$ poté značí logistickou funkci uvedenou v \ref{eq:logisticka_funkce}. Pro vypočtení optimálního parametru $\beta_i$ je nutné vypočítat
maximum funkce $L(\theta)$ vzhledem k parametru $\beta_i$. Parametr $\beta_i$ lze tedy získat derivací funkce $L(\theta)$ vzhledem k parametru $\beta_i$
\cite{kleinbaum_logistic_2010}, tedy

\begin{equation}
    \frac{\partial L(\theta)}{\partial \beta_i} = 0.
\end{equation}

\subsection{Křížová validace}
Při tvorbě logistického modelu může dojít k takzvanému přeučení modelu. To znamená, že výsledný model je velmi přizpůsobený datům, z nichž byl vytvořen, a nebude
připravený na náhodnou variaci, která může v nových datech nastat. Z tohoto důvodu se datový soubor rozděluje na dvě podmnožiny. Jedna podmnožina, většinou zvaná
\textit{trénovací},
slouží k sestavení a natrénování modelu. Model se 
následně otestuje na druhé množině dat. Druhá množina se většinou nazývá \textit{validační} nebo \textit{testovací}. 
Pokud je následně model použit na \textit{testovací} množinu dat a výsledky jsou vyhodnocené např. pomocí matice záměn, jsou zachyceny variace,
na které model není připraven, a lze tak objektivněji určit jeho kvalitu. Způsobů, jak datový soubor
rozdělit, je mnoho. Existuje například $k$-fold validace, kdy se trénovací množina dat rozdělí do $k$ 
náhodných podmnožin. Jedna podmnožina dat se použije pro validaci a zbylých $k-1$ podmnožin se použije pro trénování.
Celý proces se opakuje $k$-krát, tedy každá podmnožina bude právě jednou použita pro testování. Výsledné statistiky lze zprůměrovat a použít jako hodnocení
daného modelu \cite{hill_statistics_2006}.

\subsection{Matice záměn}
Matice záměn je nástroj pro vyhodnocení predikcí modelu. Matice má velikost $2 \times 2$. Pro potřeby logistické regrese se matice skládá ze dvou řádku a dvou sloupců.
Ve sloupcích se nacházejí původní hodnoty, tedy hodnoty, které chceme předpovídat. V řádcích se pak nacházejí předpovědi z modelu.  

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
                           &   & původní pozitivní   & původní negativní    \\ \hline
                           &   & 1                  & 0                  \\ \hline
        pozitivní predikce & 1 & skutečně pozitivní & falešně pozitivní  \\ \hline
        negativní predikce & 0 & falešně negativní  & skutečně negativní \\ \hline
    \end{tabular}
    \caption{\label{tab:matice_zamen}Matice záměn}
\end{table}

K sestavení matice je třeba množina dat, u kterých známe vysvětlovanou proměnnou. Na datech pak provedeme predikci, díky čemuž získáme predikované hodnoty. Porovnáním
původních a predikovaných hodnot vznikne matice \ref{tab:matice_zamen}. Každá ze čtyř vnitřních buněk má vlastní označení a interpretaci:

\begin{itemize}
    \item \textbf{Skutečně pozitivní} --- počet správných predikcí, které byly rovné jedné.
    \item \textbf{Falešně pozitivní} --- počet predikcí rovných jedné, kde byla původní hodnota rovná nule.
    \item \textbf{Skutečně negativní} --- počet správných predikcí, které byly rovné nule.
    \item \textbf{Falešně negativní} --- počet predikcí rovných nule, kde byla původní hodnota rovná jedné.
\end{itemize}

Z matice záměn lze následně vypočítat mnoho statistik. Pro vyhodnocení regresního modelu lze použít např. přesnost, která se vypočítá jako počet všech správných predikcí
dělený počtem všech provedených predikcí $n$.

\begin{equation}
    \textit{přesnost = } \frac{\text{skutečně pozitivní} + \text{skutečně negativní}}{n}
\end{equation}

Přesnost udává, jaké procento objektů bylo klasifikováno správně. Pokud je ovšem poměr původních pozitivních a negativních hodnot velmi nevyrovnaný,
tato statistika není vhodná. V případě velké nevyrovnanosti predikovaných hodnot přesnost zkresluje schopnost modelu predikovat méně zastoupenou predikovanou hodnotu. 
Toto se může stát například v lékařství při identifikaci nemocného pacienta. Zde většinou dochází k velkému nepoměru mezi počtem nemocných a počtem zdravých.
V takovém případě lze použít statistiku zvanou senzitivita. Ta se rovná poměru správných pozitivních predikcí a úhrnu všech pozitivních predikcí, neboli

\begin{equation}
    \textit{senzitivita = } \frac{\text{skutečně pozitivní}}{\text{skutečně pozitivní} + \text{falešně pozitivní}}.
\end{equation}

Senzitivita tedy určuje poměr správně klasifikovaných pozitivních případů a všech pozitivně klasifikovaných případů. Pokud by bylo vhodné preferovat
spíše negativní klasifikace, tedy zdravé pacienty, lze použít statistiku zvanou specificita, která je definovaná jako

\begin{equation}
    \textit{specificita = } \frac{\text{skutečně negativní}}{\text{skutečně negativní} + \text{falešně negativní}}.
\end{equation}

\subsection{Testování hypotéz}
Testování hypotéz slouží ke zjištění, zda se charakteristika $\theta$ v populaci za určitých podmínek mění. Statistická hypotéza
je definována jako předpoklad o náhodné veličině. Nulová hypotéza představuje aktuální stav veličiny.
Značí se jako $H$ či $H_0$. Hypotéza, jež se od aktuálního stavu nějakým způsobem odlišuje, se nazývá alternativní hypotéza
a značí se $H_1$, popřípadě $H_A$. Nulová hypotéza $H_0$ a testovaná hypotéza $H_1$ se navzájem vylučují. Testování hypotéz je
pak rozhodovací postup, který určí platnost právě jedné testované hypotézy. Rozhodnutí, zda platí testovaná, či alternativní hypotéza,
pak záleží na testovacím kritériu $T$. Testovacím kritériem $T$ je náhodná veličina se známým pravděpodobnostním rozdělením.

Testovací kritérium $T$ může být přiřazeno do dvou podmnožin. První množina, zvaná obor přijetí, odpovídá množině charakteristik $\theta$
při platné nulové hypotéze $H_0$. Druhá množina se nazývá kritický obor a obsahuje charakteristiky $\theta$ tak extrémní, že je 
pravděpodobnost jejich výskytu velmi malá. Pokud testovaná charakteristika $\theta$ vypočtená z náhodného výběru padne do oboru přijetí,
lze usoudit, že test neprokázal nepravdivost alternativní hypotézy. Pokud naopak padne testovací kritérium do kritického oboru, nulová
hypotéza je zamítnutá ve prospěch hypotézy alternativní.

Při zamítnutí nebo přijmutí alternativní hypotézy vznikají chyby dvojího typu. První typ chyby je nazýván \textit{hladina významnosti} a značí
se $\alpha$. \textit{Hladina významnosti} je pravděpodobnost chybného přijmutí alternativní hypotézy. Platí tedy, že testovací kritérium $T$ 
s pravděpodobností $\alpha$ padne do kritického oboru, ačkoliv patří do oboru přijetí. Chyba druhého typu pak říká, s jakou pravděpodobnostní
padne testovací kritérium $T$ do oboru přijetí, ačkoliv patří do kritického oboru. Chyba druhého typu se značí jako $\beta$. Jedná se o doplněk \textit{hladiny významnosti},
tedy $\beta = 1 - \alpha$.

Pro určení, zda kritická hodnota patří do oboru přijetí, či do kritického oboru, slouží známé pravděpodobnostní rozdělení testovaného kritéria.
Pokud testované kritérium patří do kritického oboru o velikosti $\alpha$, je nulová hypotéza zamítnuta. Hladinu významnosti $\alpha$ lze změnit.
S růstem hladiny významnosti se zmenšuje kritický obor a zároveň zvětšuje pravděpodobnost chyby prvního řádu
\cite{hebak_praktikum_2009}.

\subsection{Waldův test}
Waldův test ověřuje hypotézu, zda je parametr logistického regresního modelu $\beta_i$ rovný nule.

\begin{align}
    \begin{split}
        H_0 &: \beta_i = 0 \\
        H_1 &: \beta_i \neq 0
    \end{split}
\end{align}

Testovací kritérium Waldova testu se vypočítá odhadnutého vydělením parametru $\beta_i$ jeho standardní chybou $S_{\beta_i}$

\begin{align}
    \begin{split}
        T = \frac{\hat{\beta_i}}{S_{\hat{\beta_i}}}.
    \end{split}
\end{align}

Testovací kritérium má pravděpodobnostní rozdělení chí-kvadrát se dvěma stupni volnosti, tedy $\chi^2$. Pokud testovací kritérium patří do 
kritického oboru $\chi^2_\alpha$, hypotéza o nulovém parametru $\beta_i$ je zamítnuta ve prospěch alternativní hypotézy. Pokud testovací kritérium nepadne do kritického oboru,
tedy padne do oboru přijetí, lze usoudit, že test neprokázal platnost alternativní hypotézy \cite{kleinbaum_logistic_2010}, \cite{powers_statistical_2000}.