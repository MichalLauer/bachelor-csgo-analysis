\chapter{Teoretická část}
V následující části jsou popsány jak teoretické metody pro vizualizaci dat, tak i tvar, forma a vyhodnocení logistického regresního modelu. 
Ke každé části, která se věnuje popisu dat pomocí nějakého grafu, je přidána praktická ukázka s popisem a praktickým vysvětlením.
vhodné.

\section{Vizualizace dat} \label{sec:vizualizace_dat}
\subsection{Bodový graf}
Bodový graf slouží pro zobrazení vztahu dvou kvantitativních proměnných. Z pravidla se vysvětlovaná proměnná dává na osu Y,
zatímco proměnná vysvětlující se nachází na ose X. Vysvětlovaná (nezávislá) proměnná je ta proměnná, která má být předvídaná.
Vysvětlující proměnná se naopak snaží vysvětlovanou proměnnou předpovědět či popsat. 
{\color{red}
Zobrazením
} vysvětlované a vysvětlující proměnné
na bodovém grafu lze vidět např. sílu korelace nebo vztah mezi proměnnými (např. lineární, kvadratický, logaritmický).

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/bodovy_graf_mtcars.png}
    \caption{Bodový graf hmotnosti a míly za galon} 
    \label{fig:bodovy_graf_mtcars}
\end{figure}

Obrázek \ref{fig:bodovy_graf_mtcars} zobrazuje negativní korelaci mezi hmotností vozidla a mílemi ujetými za galon.

\subsection{Sloupcový graf}
Sloupcový graf slouží k zobrazení
{\color{red}
četností
} kategorií. Na jednu osu (z pravidla osu X) se položí možné kategorie. Na druhou osu
se pak položí sledovaná statistika.
Sledovat můžeme nejen četnost, ale i průměr či kteroukoli jinou statistiku, kterou bude možné na ose zobrazit.


Nejčastější se pomocí sloupcového grafu porovnává absolutní četnost přes kategorie. Řazení kategorií se dále odvíjí podle toho, zda je
daná proměnná ordinální či nominální. V případě nominální proměnné se sloupce řadí podle absolutní četnost
{\color{red}
, a to od nejvyšší po nejnižší.
}
. V případě ordinální
proměnné se zachovává přirozené řazení.
Příklad sloupcového grafu je zobrazen na obrázku 
{\color{red}
\ref{fig:sloupcovy_graf_mtcars}
}, který porovnává průměrnou hrubou koňskou sílu s počtem válců.
Je na něm také vidět závislost hrubé koňské síly na počtu válců.

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/sloupcovy_graf_mtcars.png}
    \caption{Sloupcový graf počtu válců a průměrné hrubé koňské síly} 
    \label{fig:sloupcovy_graf_mtcars}
\end{figure}

\subsection{Histogram}

Histogram je speciální typ sloupcového grafu. Hlavní rozdíl je v tom, že popisuje rozdělení spojité proměnné a mezi sloupci není žádná mezera.
Pro histogram je třeba data sloučit do skupin o určité šířce. Správný výběr počtu skupin je kritický, jelikož může velmi
silně ovlivnit interpretaci dat. Pokud se vybere příliš malý počet skupin, data se seskupí a může se ztratit důležitý vztah. Pokud se ovšem
vybere moc velký počet skupin, v datech bude obtížné najít nějaký obecný vztah či trend,
{\color{red}
viz obrázek \ref{fig:histogram_porovnani_mtcars}
}
\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/histogram_porovnani_mtcars.png}
    \caption{Porovnání histogramů s různým počtem skupin} 
    \label{fig:histogram_porovnani_mtcars}
\end{figure}

Pro vhodný počet skupin existuje mnoho způsobů. Nejznámější je takzvané Sturgesovo pravidlo, které se spočítá následujícím vztahem:

\begin{equation}
    \label{eq:sturgesovo_pravidlo}
    k \text{ } \dot{\mathbf{=}} \text{ } 1 + 3,3 * log_{10}(n)
\end{equation}

kde $k$ je přibližný počet skupin a $n$ je počet pozorování. Druhý parametr, který je pro tvorbu histogramu potřeba, je šířka skupiny.
Ta by měla být ideálně stejná pro všechny skupiny. Pokud tomu tak není, histogram může být zavádějící a čtenář mu nemusí plně rozumět.
Pro vypočtení počtu skupin má šířka skupiny následující tvar:

\begin{equation*}
    w = \frac{max(X) - min(X)}{k}
\end{equation*}

kde $X$ je zobrazovaná proměnná, $k$ je počet skupin a $w$ je výsledná šířka intervalu. 
Nutné je však podotknout, že není pravidlem se danými výpočty řídit a výsledný
sloupcový graf je nutné přizpůsobit
{\color{red}
konkrétnímu datovému souboru.
}

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/histogram_mtcars_sturges.png}
    \caption{Histogram s počtem skupin dle Sturgesova pravidla} 
    \label{fig:histogram_mtcars_sturges}
\end{figure}

{\color{red}
Obrázek \ref{fig:histogram_mtcars_sturges} ukazuje histogram proměnné míle za galon. Počet sloupců je vypočítán podle Sturgesova pravidla \ref{eq:sturgesovo_pravidlo} 
}

\subsection{Krabičkový graf}
\subsubsection{Five-number summary}
Five-number summary je číselná tabulka, která pomocí pěti různých čísel shrnuje seřazenou číselnou řadu. Základní statistický nástroj pro
vytvoření takové tabulky jsou kvantily. Hodnota $P$-tého percentilu označuje číslo, které rozděluje seřazenou číselnou řadu na dva intervaly. 
První interval obsahuje $P*100\%$ číselné řady a druhý analogicky $(1-P)*100\%$. Různé hodnoty percentilů mohou mít specifičtější pojmenování a značí se $Q_P$.
Percentil $P = 0,5$ se označuje jako medián a rozděluje seřazenou číselnou řadu na polovinu. Percentily, kde $P = 0,25$ nebo $P = 0,75$, se označují
jako kvartily a značí se $Q_{1}$ a $Q_{3}$. Oba tyto typy kvartilů jsou použité při tvorbě Five-number summary tabulky.

\begin{table}[H]
    \centering
    \begin{tabular}[t]{c|c|c|c|c}
        \hline
        $Q_{0} (Q_0)$ & $Q_{0,25} (Q_1) $ & $Q_{0,50}$ & $Q_{0,75} (Q_3)$ & $Q_{1,00}$\\
        \hline
        1,513 & 2,58125 & 3,325 & 3,61 & 5,424\\
        \hline
    \end{tabular}
    \caption{\label{tab:five-number_summary}Five-number summary tabulka hmotnosti vozidla (lb/1000)}
\end{table}

{\color{red}
Příkladem Five-number summary je tabulka \ref{tab:five-number_summary},
}
kde $Q_{0}$ a $Q_{1,00}$ označují minimum a maximum číselné řady. Kvartily $Q_{1}$, $Q_{2}$ (medián) a $Q_{3}$ jsou čísla, která rozděluji časovou řadu na na čtvrtiny. V prvním
případě, tedy $Q_1 = Q_{0,25}$, je 25\% čísel menší než 1,513 a 75\% dat větší. Pro kvantil $Q_3 = Q_{0,75}$ je 75\% čísel menších než 3,61 a 25\% větších. $Q_{0,50}$ označuje medián.

\subsubsection{Krabičkový graf}
Krabičkový graf je grafické zobrazení a rozšíření Five-number summary tabulky. Kromě grafického zobrazení 
pěti kvantilů  ukazuje odlehlé a extrémní hodnoty.
V Krabičkovém grafu se také nachází obdélník, který ukazuje mezikvartilové rozpětí (IQR), tedy prostředních 50 \% dat. V obdélníku se také nachází černá čára, která značí medián.
Z prostředního obdélníku vedou oběma směry čáry, jejichž konce značí hranici pro odlehlá pozorování. Pokud datový soubor neobsahuje žádná odlehlá pozorování, konec těchto čar
značí minimum a maximum datového souboru.
Pozorování, která jsou buď větší než horní hranice, nebo menší než spodní hranice, označujeme jako 
{\color{red}
odlehlá
}
nebo extrémní. 

\begin{align*}
    \textit{Spodní hranice } &= Q_1 - 1,5 * IQR \\
    \textit{Horní hranice } &= Q_3 + 1,5 * IQR
\end{align*}

Hodnoty, které spadají do intervalu $\langle Q_1 - 1,5IQR; Q_1 - 3IQR\rangle$ a $\langle Q_3 + 1,5IQR, Q_3 + 3IQR \rangle$ se nazývají jako odlehlé.
Hodnoty které leží mimo tento vztah, tedy hodnoty menší než $Q_1 - 3IQR$ nebo větší než $Q_3 + 3IQR$ se nazývají jako hodnoty extrémní.
{\color{red}
Odlehlá pozorování se v krabičkovém grafu většinou značí kolečkem, zatím co pozorování extrémní hvězdičkou.
}
Díky grafickému zobrazení lze lehce porovnávat rozdělení jedné vysvětlované kvantitativní proměnné tříděné přes několik kategorií.

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/krabickovy_graf_mtcars.png}
    \caption{Krabičkový graf hmotnosti auta pro různý počet válců} 
    \label{fig:krabickovy_graf_mtcars}
\end{figure}

Průhledná kolečka v obrázku \ref{fig:krabickovy_graf_mtcars} v kategorii osmi válců značí odlehlé hodnoty, t.j. hodnoty
v intervalu $\langle Q_3 + 1,5IQR, Q_3 + 3IQR \rangle$.


\subsection{Korelační matice}
\subsubsection{Korelace}
Korelace popisuje směr a sílu vztahu mezi dvěma proměnnými $X$ a $Y$. Značí se $r$ a nabývá hodnot $\langle -1; 1 \rangle$.

\begin{equation*}
r = \frac{n \sum_{i=1}^n x_i y_i - \sum_{i=1}^n x_i \sum_{i=1}^n y_i}
{\sqrt{(\overline{x^2} - \overline{x}^2)(\overline{y^2} - \overline{y}^2)}}
\end{equation*}

Čím větší je absolutní hodnota korelace mezi proměnnou $X$ a $Y$, tím lépe lze pomocí jedné proměnné vysvětlit proměnnou druhou. Kladnost, případně zápornost korelace
značí pak směr vztahu. Pokud je korelace záporná, tedy $r < 0$, s růstem jedné proměnné klesá proměnná druhá. Naopak při kladné korelace, tedy $r > 0$, s růstem
jedné proměnné roste i druhá.
{\color{red}
Pokud se korelace $r$ vychází kolem nuly, neexistuje lineární závislost mezi proměnnou $X$ a $Y$. Důležité je také podotknout, že korelace neznamená kauzalitu. Pokud
existuje kladná korelace mezi proměnnou $X$ a $Y$, neznamená to, že růst jedné proměnné způsobil růst druhé proměnné.  
}

\subsubsection{Korelační matice}
Korelační matice je nástroj, díky kterému lze zobrazit korelaci mezi více jak dvěma páry proměnných. Matice může být zobrazená
{\color{red}
pomocí grafu.
}
Korelační matice je velmi užitečná v regresní analýze kvůli předpokladu nezávislosti
{\color{red}
vysvětlujících proměnných v analýze.
}
Pokud jsou při tvorbě modelu prediktory korelované,
vzniká problém tzn. multikolinearity. Při multikolinearitě se zhoršuje přesnost a vypovídací hodnota koeficientů \cite{kleinbaum_logistic_2010}.
V takovém případě je potřeba zvýšit počet pozorování nebo z modelu určité prediktory odebrat. 

\begin{figure}[H]
    \centering
    \includegraphics{../obrazky/mtcars_korelace.png}
    \caption{Korelační matice} 
    \label{fig:mtcars_korelace}
\end{figure}

Graf korelační matice může mít mnoho podob. V příkladu obrázku \ref{fig:mtcars_korelace} je zobrazená korelační matice jako teplotní mapa. Z obrázku je možné pozorovat vysokou
pozitivní korelaci mezi páry proměnných \textit{cyl}, \textit{disp} a \textit{hp}. Naopak skoro žádná korelace není mezi proměnnou \textit{qsec} a proměnnou \textit{drat}.
Korelační matice je zároveň symetrická, jelikož korelace mezi $X$ a $Y$ je stejná jako korelace mezi $Y$ a $X$. Díky této vlastnosti je možné zobrazit pouze část 
korelační matice pod úhlopříčkou bez ztráty jakékoliv informace.


\newpage
\section{Logistická regrese}
Logistická regrese je způsob, jak popsat vztah mezi jedním či několika prediktory a jednou binární vysvětlovanou 
proměnnou. K tomu slouží spojovací funkce, která transformuje lineární kombinaci prediktorů na index $z$. V případě
logistické regrese se tato funkce nazývá logistická a je definovaná jako

\begin{equation}
    \label{eq:logisticka_funkce}
    f(z) = \frac{1}{1 + e^{-z}}.
\end{equation}

Obor hodnot funkce je interval $\langle 0, 1 \rangle$. Proměnná $z$ je lineární kombinace prediktorů  $X_1, X_2, ..., X_k$, 
jejich koeficientů $\beta_1, \beta_2, ..., \beta_k$ a parametru $\alpha$.

\begin{equation*}
    \label{eq:linearni_kombinace_z}
    \begin{split}
        z &= \alpha + \beta_1 X_1 + ... + \beta_2 X_2 +\beta_k X_k \\
          &= \alpha + \sum_{i=1}^k \beta_i X_i
    \end{split}
\end{equation*}

Mějme tedy binární vysvětlovanou proměnnou $Y$, u které hodnota $1$ značí výskyt jevu. Pravděpodobnost, že jev nastane
vzhledem k definovaným prediktorům lze zapsat jako

\begin{equation}
    \label{eq:pravdepodobnost_y}
    P(Y = 1 \mid X_1, X_2, ..., X_k) = \frac{1}{1 + e^{- \left( \alpha + \sum_{i=1}^k \beta_i X_i \right) }},
\end{equation}

kde $\alpha$ a $\beta_i$ jsou parametry odhadnuté z datového souboru. \cite{kleinbaum_logistic_2010}

\subsection{Interpretace parametrů}
Parametry $\alpha$ a $\beta_i$ značí logaritmus šance. $\alpha$ je logaritmus šance v případě, že všechny prediktory
jsou teoreticky rovné $0$. Parametr $\beta_i$ značí logaritmus šance pro prediktor $X_i$
V případě, že všechny prediktory jsou konstantní a prediktor $X_i$ se změní o jednotku, přirozený logaritmus
šance se změní o $B_i$. Toto lze pozorovat například u binárních prediktorů, kdy typicky přítomnost
daného prediktoru, značená jedničkou, změní výslednou šanci právě o odhadnutý parametr $\beta$.
Pro přechod z přirozeného logaritmu šance na šanci lze využít vztahu

\begin{equation*}
\textit{šance } = e^{\beta_i}.
\end{equation*}

Šance je podíl dvou pravděpodobností. Pokud bychom měli šanci jevu A oproti jevu B $2 : 1$, značí to, že výskyt jevu A je dvakrát tak pravděpodobný
jako výskyt jevu B a jev A se vyskytuje ve $\frac{2}{3}$ případů. Šance $e^{\beta_i}$ tedy značí vztah mezi prediktorem $X_i$ a vysvětlovanou proměnnou $Y$. Pokud je
šance kladná, značí to, že s vyšší hodnotou prediktoru $X_i$ se zvyšuje šance že $P(Y = 1)$. Pokud je naopak nižší, pravděpodobnost se zmenšuje. Pokud je potřeba
interpretovat pravděpodobnost jako šanci, použije se logitová funkce

\begin{equation*}
    \label{eq:logitova_funkce}
    \textit{šance jevu A} = \frac{p}{1 - p}
\end{equation*}

kde $p$ je pravděpodobnost výskytu jevu A.

\subsection{Největší pravděpodobnost}
Parametry logistického modelu v rovnici \ref{eq:pravdepodobnost_y} jsou pouze teoretické a je třeba je odhadnout. Již vypočtené odhady
se proto neznačí pouze $\beta$, ale $\hat{\beta}$. Pro odhad parametrů se při logistické regresi používá metoda maximální věrohodnosti. Pro výpočet
maximální věrohodnosti se počítá věrohodnostní funkce $L(\theta)$ kde $\theta$ jsou parametry logistického modelu $\alpha, \beta_1, ..., \beta_k$.
Pro logistickou regresi má věrohodnostní funkce tvar

\begin{equation*}
    \label{eq:pravdepodobnostni_fce}
    L(\theta) = \Pi_{l = 1}^{m_1} P(X_i) \Pi_{l = m_1 + 1}^{n} 1 - P(X_i),
\end{equation*}

kde $n$ je počet pozorování a $m_1$ je počet příznivých ($Y = 1$) jevů. Funkce předpokládá, že datový soubor je seřazen tak, že prvních $m_1$ výskytů
jsou jevy příznivé. $P(X_i)$ poté značí logistickou funkci \ref{eq:logisticka_funkce}. Pro vypočtení optimálního parametru $\beta_i$ je nutné vypočítat
maximum funkce $L(\theta)$ vzhledem k parametru $\beta_i$. Parametr $\beta_i$ lze tedy získat derivací funkce $L(\theta)$ vzhledem k parametru $\beta_i$. \cite{kleinbaum_logistic_2010}

\begin{equation*}
    \frac{\partial L(\theta)}{\partial \beta_i} = 0
\end{equation*}


\subsection{Křížová validace}
Při
{\color{red}
tvorbě
}
logistické modelu může dojít k takzvanému přeučení modelu. To znamená, že výsledný model je velmi přizpůsobený na data, ze kterých byl vytvořen, a nebude
připravený na náhodnou variaci, která může v nových datech nastat. Z tohoto důvodu se datový soubor rozděluje na dvě podmnožiny. Jedna podmnožina, většinou zvaná
\textit{trénovací},
slouží k sestavení a natrénování modelu. 
{\color{red}
Model se pak otestuje 
}
na druhé množině dat, na kterou nebyl natrénovaný. Druhá množina se většinou nazývá \textit{validační} nebo \textit{testovací}. 
{\color{red}
Pokud je následně model vyhodnocen např. pomocí matice záměn, jsou zachycené variace, na které model není připraven a lze tak objektivněji určit kvalitu
modelu. Způsobů, jak datový soubor
}
rozdělit, je mnoho. Existuje například $k$-fold validace, kdy se trénovací množina dat rozdělí na $k$ 
{\color{red}
náhodných podmnožin. Jedna podmnožina dat se použije pro validaci a zbylých $k-1$ podmnožin se požije pro trénování.
Celý proces se opakuje $k$ krát, tedy každá podmnožina bude právě jednou použita pro testování. Výsledné statistiky lze zprůměrovat a použít jako hodnocení
daného modelu.
}

\subsection{Matice záměn}
Matice záměn je nástroj pro vyhodnocení predikcí modelu. Matice je o velikosti $2 \times 2$. Pro potřeby logistické regrese se matice skládá ze dvou řádku a dvou sloupců.
{\color{red}
Ve sloupcích se nachází původní hodnoty, tedy hodnoty, které chceme předpovídat. Ve řádcích se pak nachází předpovědi z modelu.  
}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
                           &   & Původní pozitivní   & Původní negativní    \\ \hline
                           &   & 1                  & 0                  \\ \hline
        Pozitivní predikce & 1 & Skutečně pozitivní & Falešně pozitivní  \\ \hline
        Negativní predikce & 0 & Falešně negativní  & Skutečně negativní \\ \hline
    \end{tabular}
    \caption{\label{tab:matice_zamen}Matice záměn}
\end{table}

Pro sestavení matice je potřeba množina dat, u kterých známe vysvětlovanou proměnnou. Na datech pak provedeme predikci, díky čemuž získáme predikované hodnoty. Porovnáním
původních a predikovaných hodnot vznikne matice \ref{tab:matice_zamen}. Každá ze čtyř vnitřních buněk má vlastní označení a interpretaci:

\begin{itemize}
    \item \textbf{Skutečně pozitivní} --- počet správných predikcí, které byly rovné jedné.
    \item \textbf{Falešně pozitivní} --- počet predikcí rovných jedné, kde byla původní hodnota rovná nule.
    \item \textbf{Skutečně negativní} --- počet správných predikcí, které byly rovné nule.
    \item \textbf{Falešně negativní} --- počet predikcí rovných nule, kde byla původní hodnota rovná jedné.
\end{itemize}

Z matice lze následně vypočítat mnoho statistik. Pro vyhodnocení regresního modelu lze použít např. přesnost, která se vypočítá jako počet všech správných predikcí nad
počtem všech provedených predikcí $n$.

\begin{equation*}
    \textit{Přesnost = } \frac{\text{Skutečně pozitivní} + \text{Skutečně negativní}}{n}
\end{equation*}


Přesnost říká, jaké procento
{\color{red}
objektů
}
bylo klasifikováno správně. Pokud je ovšem poměr původních pozitivních a negativních hodnot velmi nevyrovnaný, tato statistika
není vhodná. Toto se může stát například v lékařství při identifikaci nemocného pacienta. Zde většinou dochází k velkému nepoměru mezi počtem nemocných a počtem zdravých.
V takovém případě lze použít statistiku zvanou senzitivita. Ta se rovná poměru správných pozitivních predikcí a úhrnu všech pozitivních predikcí

\begin{equation*}
    \textit{Senzitivita = } \frac{\text{Skutečně pozitivní}}{\text{Skutečně pozitivní} + \text{Falešně pozitivní}}
\end{equation*}

Senzitivita tedy určuje poměr správně klasifikovaných pozitivních případů a všech pozitivně klasifikovaných případů. Pokud by bylo vhodné preferovat
spíše negativní klasifikace, tedy zdravé pacienty, lze použit statistiku zvanou specificita.

\begin{equation*}
    \textit{Specificita = } \frac{\text{Skutečně negativní}}{\text{Skutečně negativní} + \text{Falešně negativní}}
\end{equation*}

{\color{red}
\subsection{Testování hypotéz}
Cílem testovací hypotézy je zjistit, zda neznámý parametr $\theta$ patří do nějaké prostoru $\Omega_0$. Testuje se nultá hypotéza, značená $H_0$, která říká, že
parametr do prostoru $\theta$ do prostoru $\Omega_0$ patří. Proti ní je postavená hypotéza alternativní, značená $H_1$, která tvrdí, že parametr $\theta$ do prostoru
$\Omega_0$ nepatří. Pro tetování je nutné zvolit parametr $\alpha$, který značí hodnotu chyby prvního druhu. Chyba prvního druhu stanovuje, jaká je pravděpodobnost, že se zamítne
testovaná nultá hypotéza $H_0$ za předpokladu, že je $H_0$ pravdivá \cite{hardle_applied_2015}.

\begin{equation*}
    P(\text{Zamítnutní }H_0 | H_0\text{ je platná}) = \alpha
\end{equation*}

Existuje také chyba druhého typu $\beta$, která značí pravděpodobnost nezamítnutí neplatné nulové hypotézy.

\begin{equation*}
    P(\text{Nezamítnutí }H_0 | H_0\text{ je neplatná}) = \beta
\end{equation*}

Chyby nelze eliminovat a je nutné je s nimi při testování hypotézy počítat. Pro parametr $\alpha$ se ustálily hodnoty $0.1, 0.05$ a $0.01$.
}

\subsection{Waldův test}
{\color{red}
Koeficienty v logistickém regresním modelu nemusí být statisticky významné. Pokud je prediktor nevýznamný, znamená to, že není významný při predikci prediktoru.
K otestování významnosti prediktoru lze použít Waldův test.
}
Waldův test ověřuje, zda je parametr $\beta_i$ v populaci významný či nikoliv. Definice testu hypotézy je tedy:

$H_0:$ Koeficient $\beta_i$ je rovný nule. \\
$H_A:$ Koeficient $\beta_i$ je různý od nuly.

Pro vyhodnocení hypotézy se používá
{\color{red}
testové kritérium
}
$Z$, který se vypočítá jako poměr testovaného parametru $\beta_i$
a směrodatné chyby koeficientu $S_{\hat{\beta_i}}$

\begin{equation*}
    Z = \frac{\hat{\beta_i}}{S_{\hat{\beta_i}}}.
\end{equation*}

{\color{red}
Testové kritérium
}
$Z$ má za platnosti nulové hypotézy normální $N(0, 1)$ a její mocnina, $Z^2$, má chi-kvadrát rozdělení s jedním stupněm volnosti \cite{kleinbaum_logistic_2010}.
